{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Exam Solutions",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khpe_GaOLl5F"
      },
      "source": [
        "##Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjoglpCFILz3",
        "outputId": "b572debd-57cc-45b2-dcc8-e8d52efe1abd"
      },
      "source": [
        "!git clone https://github.com/CSSEGISandData/COVID-19.git\r\n",
        "!rm -rf COVID-19/.git\r\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'COVID-19' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa2lSZHrKVgN"
      },
      "source": [
        "data_path=\"./COVID-19/\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0imcjXqLvbg"
      },
      "source": [
        "##Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uXafJzNK_oH"
      },
      "source": [
        "!ls $data_path/csse_covid_19_data/csse_covid_19_daily_reports\r\n",
        "\r\n",
        "import glob\r\n",
        "us_files=glob.glob(data_path+\"csse_covid_19_data/csse_covid_19_daily_reports_us/*.csv\")\r\n",
        "all_files=glob.glob(data_path+\"csse_covid_19_data/csse_covid_19_daily_reports/*.csv\")\r\n",
        "print(len(us_files),len(all_files))\r\n",
        "\r\n",
        "# Extract date string from filesname\r\n",
        "a_date_string= all_files[0].split(\"/\")[-1].split(\".\")[0]\r\n",
        "print(a_date_string)\r\n",
        "\r\n",
        "import datetime,time\r\n",
        "time.mktime(datetime.datetime.strptime(a_date_string,\"%m-%d-%Y\").timetuple())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkQoAXL4xZJI"
      },
      "source": [
        "import datetime,time\r\n",
        "def srtbydate(files):\r\n",
        "  test=list()\r\n",
        "  new=list()\r\n",
        "  count=0\r\n",
        "  for i in range(len(files)):\r\n",
        "    a_date_string= files[i].split(\"/\")[-1].split(\".\")[0]\r\n",
        "    test.append(time.mktime(datetime.datetime.strptime(a_date_string,\"%m-%d-%Y\").timetuple()))\r\n",
        "    for j in range(len(test)):\r\n",
        "      if time.mktime(datetime.datetime.strptime(a_date_string,\"%m-%d-%Y\").timetuple())<test[j]:\r\n",
        "        new.insert(j,files[i])\r\n",
        "        break\r\n",
        "      count+=1\r\n",
        "    if count==len(test):\r\n",
        "      new.append(files[i])\r\n",
        "    count=0      \r\n",
        "  return new"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsWJ_yLm43h6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9add1d6-3679-4d3e-a0a7-d49712905196"
      },
      "source": [
        "dates=['11-04-2020.csv','12-03-2020.csv','09-03-2020.csv','03-05-2020.csv']\r\n",
        "print(srtbydate(dates))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['03-05-2020.csv', '09-03-2020.csv', '11-04-2020.csv', '12-03-2020.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx-jN2Ar-FMS"
      },
      "source": [
        "##Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCC-BHxa-IiA",
        "outputId": "15496125-a814-4bd2-cbf0-daedc54717fb"
      },
      "source": [
        "import pandas as pd\r\n",
        "df = pd.read_csv(all_files[0])\r\n",
        "df['Confirmed'][3405]\r\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "08XTrkMe_8eJ",
        "outputId": "dcadb256-4d33-44b8-9474-775bc2caa171"
      },
      "source": [
        "all_files[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-23-2020.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG-IkXIaAMKQ"
      },
      "source": [
        "import pandas as pd\r\n",
        "def data(files):\r\n",
        "  \r\n",
        "  province_state=''\r\n",
        "  country_region=''\r\n",
        "  lat=list()\r\n",
        "  long_=list()\r\n",
        "  Confirmed=list()\r\n",
        "  Deaths=list()\r\n",
        "  Recovered=list()\r\n",
        "  Active=list()\r\n",
        "  data_structure=dict()\r\n",
        "  #Dont really need the admin or fips columns in the data structure     \r\n",
        "  for j in range(3406):\r\n",
        "      for i in range(len(files)):\r\n",
        "        df = pd.read_csv(all_files[i])\r\n",
        "        \r\n",
        "        lat.append(df['Lat'][j])\r\n",
        "        long_.append(df['Long_'][j])\r\n",
        "        Confirmed.append(df['Confirmed'][j])\r\n",
        "        Deaths.append(df['Deaths'][j])\r\n",
        "        Recovered.append(df['Recovered'][j])\r\n",
        "        Active.append(df['Active'][j])\r\n",
        "       \r\n",
        "        province_state=df['Province_State'][j]\r\n",
        "        country_region=df['Country_Region'][j]\r\n",
        "      if province_state==None:\r\n",
        "        semi={country_region: {'Latitude':lat ,'Longitude':long_ ,\r\n",
        "                                  'Confirmed':Confirmed ,'Deaths':Deaths ,\r\n",
        "                                  'Recovered':Recovered ,'Active':Active }}\r\n",
        "        data_structure.update(semi)\r\n",
        "      else:\r\n",
        "        semi={province_state+','+country_region: {'Latitude':lat,'Longitude':long_,'Confirmed':Confirmed,'Deaths':Deaths,'Recovered': Recovered ,'Active': Active }}\r\n",
        "        data_structure.update(semi)\r\n",
        "      \r\n",
        "      province_state=''\r\n",
        "      country_region=''\r\n",
        "      lat=list()\r\n",
        "      long_=list()\r\n",
        "      Confirmed=list()\r\n",
        "      Deaths=list()\r\n",
        "      Recovered=list()\r\n",
        "      active=list()\r\n",
        "\r\n",
        "      return data_structure"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f_smRw3XlIv"
      },
      "source": [
        "data(all_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsKnQthEVoRd"
      },
      "source": [
        "##Question 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slsqboNTXkE3"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "df['Deaths'].plot_date()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmSHu4HjVqAj"
      },
      "source": [
        "def time_series_plot(data,area,field):\r\n",
        "  data[area][field].plot()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw7yrihJCtlK"
      },
      "source": [
        "##Question 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh8o4bldCvwZ"
      },
      "source": [
        "def aggregate(regions,data):\r\n",
        "  confirmed=0\r\n",
        "  deaths=0\r\n",
        "  recovered=0\r\n",
        "  active=0\r\n",
        "\r\n",
        "  aggregate=dict()\r\n",
        "  #Have to get number of dates down \r\n",
        "  for i in range(len(regions)):\r\n",
        "     confirmed=sum(data[i][Confirmed])   \r\n",
        "     deaths=sum(data[i][Deaths])\r\n",
        "     recovered=sum(data[i][Recovered])\r\n",
        "     active=sum(data[i][Active])\r\n",
        "     aggregate.update(regions[[i],{'Confirmed': confirmed,'Deaths': deaths, 'Recovered': recovered, 'Active': active}])      \r\n",
        "  return aggregate\r\n",
        "\r\n",
        "#Wasnt able to get the bug from #3 fixed so I cant test or aggregate the data given"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN51sMKsCw3Q"
      },
      "source": [
        "##Question 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uftpdj1SCy1L"
      },
      "source": [
        "import pandas as pd \r\n",
        "  #using the region and the data I am goign to find the first date in which someone was cofirmed\r\n",
        "  #lookign for greater than 1\r\n",
        "time_ordered=list()\r\n",
        "  ##using the all files data \r\n",
        "for i in range(len(all_files)):\r\n",
        "  df = pd.read_csv(all_files[i])\r\n",
        "  for j in range(3406):\r\n",
        "    if df['Confirmed'][j]>0:\r\n",
        "      time_ordered.append(df['Confirmed'][j])\r\n",
        "  #Since the csv are already in order the list will be built on date order by itself"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O9gKoSWCzrf"
      },
      "source": [
        "##Question 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "I-o_VNa-C2WU",
        "outputId": "52242ac8-1697-4f65-df8f-6bc528c52fb1"
      },
      "source": [
        "##We will use soome loops to determine the highest peak and then back trace to th peak date\r\n",
        "import pandas as pd\r\n",
        "peak=0\r\n",
        "peak_date=''\r\n",
        "for i in range(len(all_files)):\r\n",
        "  df=pd.read_csv(all_files[i])\r\n",
        "  #For now I am just using an arbitrary country so im using the first one \r\n",
        "  if df['Confirmed'][0]>peak:\r\n",
        "    peak_date=all_files[i].split(\"/\")[-1].split(\".\")[0]\r\n",
        "peak_date\r\n",
        "#This therfore gives a peak date for a specific country"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'03-20-2020'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    }
  ]
}